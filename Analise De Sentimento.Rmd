---
title: "Analise de Sentimento"
output: html_notebook
---


```{r}
library(rvest)
library(stringr)

# Lista de stopwords em português
stopwords_pt <- c("de", "a", "o", "que", "e","é", "do", "da", "em", "um", "para", "com", "não", "uma", "os", "no", "se", "na", "por", "mais", "as", "dos", "como", "mas", "ao", "ele", "das", "à", "seu", "sua", "ou", "quando", "muito", "nos", "já", "eu", "também", "só", "pelo", "pela", "até", "isso", "ela", "entre", "depois", "sem", "mesmo", "aos", "seus", "quem", "nas", "me", "esse", "eles", "você", "essa", "num", "nem", "suas", "meu", "às", "minha", "numa", "pelos", "elas", "qual", "nós", "lhe", "deles", "essas", "esses", "pelas", "este", "dele", "tu", "te", "vocês", "vos", "lhes", "meus", "minhas", "teu", "tua", "teus", "tuas", "nosso", "nossa", "nossos", "nossas", "dela", "delas", "esta", "estes", "estas", "aquele", "aquela", "aqueles", "aquelas", "isto", "aquilo", "estou", "está", "estamos", "estão", "estive", "esteve", "estivemos", "estiveram", "estava", "estávamos", "estavam", "estivera", "estivéramos", "esteja", "estejamos", "estejam", "estivesse", "estivéssemos", "estivessem", "estiver", "estivermos", "estiverem", "hei", "há", "havemos", "hão", "houve", "houvemos", "houveram", "houvera", "houvéramos", "haja", "hajamos", "hajam", "houvesse", "houvéssemos", "houvessem", "houver", "houvermos", "houverem", "houverei", "houverá", "houveremos", "houverão", "houveria", "houveríamos", "houveriam", "sou", "somos", "são", "era", "éramos", "eram", "fui", "foi", "fomos", "foram", "fora", "fôramos", "seja", "sejamos", "sejam", "fosse", "fôssemos", "fossem", "for", "formos", "forem", "serei", "será", "seremos", "serão", "seria", "seríamos", "seriam", "tenho", "tem", "temos", "tém", "tinha", "tínhamos", "tinham", "tive", "teve", "tivemos", "tiveram", "tivera", "tivéramos", "tenha", "tenhamos", "tenham", "tivesse", "tivéssemos", "tivessem", "tiver", "tivermos", "tiverem", "faz")

limpar_texto <- function(texto) {
  # Remove caracteres especiais, pontuações, números e converte para minúsculas
  texto_limpo <- str_replace_all(texto, "[^[:alnum:][:space:]]", "")
  texto_limpo <- tolower(texto_limpo)
  
  return(texto_limpo)
}

tokenizar_texto <- function(texto) {
  # Divide o texto em palavras
  tokens <- str_split(texto, "\\s+")
  # Remove tokens vazios
  tokens <- tokens[[1]][tokens[[1]] != ""]
  
  return(tokens)
}

remover_stopwords <- function(tokens, stopwords) {
  # Remove as stopwords
  tokens_sem_stopwords <- tokens[!tokens %in% stopwords]
  
  return(tokens_sem_stopwords)
}

extrair_textos_informativos <- function(url) {
  # Faz o pedido HTTP para a página
  resposta <- read_html(url)

  # Verifica se a resposta contém conteúdo
  if (length(resposta) > 0) {
    # Encontra todos os elementos de texto informativo (por exemplo, parágrafos)
    textos_informativos <- html_nodes(resposta, "p")

    # Extrai, limpa, tokeniza, remove stopwords e imprime os textos informativos
    for (texto in textos_informativos) {
      texto_limpo <- limpar_texto(html_text(texto))
      tokens <- tokenizar_texto(texto_limpo)
      tokens_sem_stopwords <- remover_stopwords(tokens, stopwords_pt)
      print(tokens_sem_stopwords)
    }
  } else {
    cat("Falha ao acessar a página. A resposta não contém conteúdo.\n")
  }
}

# Lista de URLs que você deseja raspar
urls <- c(
  "https://diplomatique.org.br/do-bolsodoria-ao-bolsonarovirus-o-discurso-de-joao-doria/",
  "https://agenciamural.org.br/panorama-da-covid-19-na-grande-sao-paulo/",
  "https://jornal.usp.br/ciencias/bolhas-de-protecao-local-podem-ter-freado-covid-19-em-sao-paulo-aponta-pesquisa/",
  "https://vejasp.abril.com.br/saude/sao-paulo-900-mil-casos-covid-19?utm_source=google&utm_medium=cpc&utm_campaign=eda_vejasp_audiencia_institucional&gad_source=1&gclid=Cj0KCQiA6vaqBhCbARIsACF9M6nG3mRC82T1K2T4jKti86xQqVQQW2ToCM5NZhw5ORagaiFKIQzqCuMaAsoBEALw_wcB",
  "https://www.bbc.com/portuguese/brasil-51746662",
  "https://www.bbc.com/portuguese/brasil-53588285",
  "https://brasil.elpais.com/brasil/2020-09-11/sao-paulo-puxa-queda-de-mortes-por-covid-19-no-pais-mas-e-cedo-para-cravar-controle-da-pandemia.html",
  "https://www.brasildefato.com.br/2020/06/10/autoridades-estao-mandando-populacao-para-abatedouro-com-reabertura-comercial-em-sp",
  "https://www.brasildefato.com.br/2020/06/10/autoridades-estao-mandando-populacao-para-abatedouro-com-reabertura-comercial-em-sp",
  "https://www.brasildefato.com.br/2020/07/09/vitimas-da-flexibilizacao-relatos-de-quem-contraiu-covid-na-volta-ao-trabalho-em-sp"
)

# Itera sobre a lista de URLs e aplica o web scraping para cada uma delas
for (url in urls) {
  extrair_textos_informativos(url)
}



```


